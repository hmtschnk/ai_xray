{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c0291f9-04dc-430c-9b83-2035828f35b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\affiqazrin\\Desktop\\projects\\awanpro_xray\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# --- Load JSON Config ---\n",
    "import json\n",
    "import matplotlib.cm as cm\n",
    "CONFIG_PATH = \"xray_config.json\"\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "# Model parameters\n",
    "STANDARD_OVERLAY_SIZE = tuple(CONFIG[\"model\"][\"standard_overlay_size\"])\n",
    "WEIGHT = CONFIG[\"model\"][\"weight\"]\n",
    "\n",
    "# Thresholds\n",
    "PATHOLOGY_THRESHOLD = CONFIG[\"thresholds\"][\"pathology\"]\n",
    "ANATOMY_THRESHOLD = CONFIG[\"thresholds\"][\"anatomy\"]\n",
    "\n",
    "# Disease overlay parameters\n",
    "DISEASE_BOX_COLOR = tuple(CONFIG[\"disease_overlay\"][\"box_color\"])\n",
    "DISEASE_BOX_THICKNESS = CONFIG[\"disease_overlay\"][\"box_thickness\"]\n",
    "DISEASE_ALPHA = CONFIG[\"disease_overlay\"][\"alpha\"]\n",
    "\n",
    "# Visualization parameters\n",
    "VISUAL_ALPHAS = CONFIG[\"visualization\"][\"alphas\"]\n",
    "VISUAL_COLORMAPS = [getattr(cm, name) for name in CONFIG[\"visualization\"][\"colormaps\"]]\n",
    "LABEL_MIN_DIST = CONFIG[\"visualization\"][\"label_min_dist\"]\n",
    "LABEL_OFFSET_STEP = CONFIG[\"visualization\"][\"label_offset_step\"]\n",
    "LABEL_FONTSIZE = CONFIG[\"visualization\"][\"label_fontsize\"]\n",
    "\n",
    "# ------------------------\n",
    "# XRayProcessor Class\n",
    "# ------------------------\n",
    "import os, shutil, datetime\n",
    "import torch, numpy as np, skimage.io\n",
    "from skimage.transform import resize\n",
    "import torchxrayvision as xrv\n",
    "from safetensors.torch import save_file\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "class ImagePreprocessor:\n",
    "    @staticmethod\n",
    "    def load_and_preprocess_for_display(img_path):\n",
    "        img = skimage.io.imread(img_path)\n",
    "        if len(img.shape) == 3 and img.shape[2] == 4:\n",
    "            img = img[..., :3]\n",
    "        img_normalized = img.astype(np.float32)\n",
    "        img_normalized = (img_normalized - img_normalized.min()) / (img_normalized.max() - img_normalized.min() + 1e-8)\n",
    "        return resize(img_normalized, STANDARD_OVERLAY_SIZE, anti_aliasing=True, preserve_range=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_and_preprocess_for_model(img_path, target_size):\n",
    "        img = skimage.io.imread(img_path)\n",
    "        if len(img.shape) == 3:\n",
    "            img = img.mean(2)\n",
    "        img = xrv.datasets.normalize(img, 255)\n",
    "        img = resize(img, (target_size, target_size), anti_aliasing=True, preserve_range=True)\n",
    "        return img[None, ...]\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_dicom_to_jpg(dicom_path, output_dir, jpg_filename):\n",
    "        import dicom2jpg\n",
    "        try:\n",
    "            dicom2jpg.dicom2jpg(dicom_path, output_dir)\n",
    "            for file in os.listdir(output_dir):\n",
    "                if file.lower().endswith(\".jpg\"):\n",
    "                    shutil.move(os.path.join(output_dir, file), os.path.join(output_dir, jpg_filename))\n",
    "                    return os.path.join(output_dir, jpg_filename)\n",
    "            raise FileNotFoundError(\"No JPG file found after conversion.\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error converting DICOM to JPG: {e}\")\n",
    "\n",
    "class XRayProcessor:\n",
    "    def __init__(self, xray_file, output_path, unique_id):\n",
    "        self.xray_file = xray_file\n",
    "        self.output_path = output_path\n",
    "        self.id = str(unique_id)\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        os.makedirs(self.output_path, exist_ok=True)\n",
    "        print(f\"[{now}][API] Output directory ensured: {self.output_path}\")\n",
    "        self.jpg_path = os.path.join(output_path, f\"{self.id}.jpg\")\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"[{now}][API] Using device: {self.device}\")\n",
    "        self.cls_model = xrv.models.DenseNet(weights=WEIGHT).to(self.device).eval()\n",
    "        self.seg_model = xrv.baseline_models.chestx_det.PSPNet().to(self.device).eval()\n",
    "\n",
    "    def _get_image_for_processing(self):\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        ext = os.path.splitext(self.xray_file)[-1].lower()\n",
    "        if ext == \".dcm\":\n",
    "            jpg_path = ImagePreprocessor.convert_dicom_to_jpg(self.xray_file, self.output_path, os.path.basename(self.jpg_path))\n",
    "            print(f\"[{now}][API] Converted DICOM to JPG: {jpg_path}\")\n",
    "            return jpg_path\n",
    "        elif ext in [\".jpg\", \".png\", \".jpeg\"]:\n",
    "            shutil.copy2(self.xray_file, self.jpg_path)\n",
    "            print(f\"[{now}][API] Copied image: {self.jpg_path}\")\n",
    "            return self.jpg_path\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file format. Only DICOM, JPG, PNG are supported.\")\n",
    "\n",
    "    def _analyze_pathologies(self, img_path):\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{now}][API] Analyzing image for pathologies: {img_path}\")\n",
    "        img = ImagePreprocessor.load_and_preprocess_for_model(img_path, target_size=224)\n",
    "        input_tensor = torch.from_numpy(img).unsqueeze(0).float().to(self.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.cls_model(input_tensor)\n",
    "        results = dict(zip(self.cls_model.pathologies, map(float, outputs[0].cpu().numpy())))\n",
    "        print(f\"[{now}][API] Pathology analysis complete.\")\n",
    "        return results\n",
    "\n",
    "    def _generate_disease_overlays(self, img_path, original_image):\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{now}][API] Generating disease overlays.\")\n",
    "        img = ImagePreprocessor.load_and_preprocess_for_model(img_path, target_size=224)\n",
    "        input_tensor = torch.from_numpy(img).unsqueeze(0).float().to(self.device)\n",
    "        target_layer = self.cls_model.features.denseblock3.denselayer16.conv2\n",
    "        cam = GradCAM(model=self.cls_model, target_layers=[target_layer])\n",
    "\n",
    "        if len(original_image.shape) == 2:\n",
    "            original_image_rgb = np.stack([original_image]*3, axis=-1)\n",
    "        else:\n",
    "            original_image_rgb = original_image.copy()\n",
    "\n",
    "        overlays = { \"original_display_image\": torch.from_numpy(original_image_rgb).float() }\n",
    "\n",
    "        for i, pathology in enumerate(self.cls_model.pathologies):\n",
    "            grayscale_cam = cam(input_tensor=input_tensor, targets=[ClassifierOutputTarget(i)])[0]\n",
    "            norm_heatmap = (grayscale_cam - grayscale_cam.min()) / (grayscale_cam.max() - grayscale_cam.min() + 1e-8)\n",
    "            cam_resized = resize(norm_heatmap, STANDARD_OVERLAY_SIZE, preserve_range=True)\n",
    "            cam_rgb = np.stack([cam_resized]*3, axis=-1)\n",
    "            boxed_img = (1-DISEASE_ALPHA)*original_image_rgb + DISEASE_ALPHA*cam_rgb\n",
    "            mask = cam_resized >= PATHOLOGY_THRESHOLD\n",
    "            mask_uint8 = (mask.astype(np.uint8)*255)\n",
    "            contours, _ = cv2.findContours(mask_uint8, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "            if contours:\n",
    "                contour = max(contours, key=cv2.contourArea)\n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                boxed_img_uint8 = (boxed_img*255).astype(np.uint8)\n",
    "                cv2.rectangle(boxed_img_uint8, (x, y), (x+w, y+h), DISEASE_BOX_COLOR, DISEASE_BOX_THICKNESS)\n",
    "                overlays[pathology] = torch.from_numpy(boxed_img_uint8/255.0).float()\n",
    "            else:\n",
    "                overlays[pathology] = torch.from_numpy(boxed_img).float()\n",
    "        print(f\"[{now}][API] Disease overlays generated.\")\n",
    "        return overlays\n",
    "\n",
    "    def _generate_anatomical_overlays(self, img_path, original_image):\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        print(f\"[{now}][API] Generating anatomical overlays.\")\n",
    "        img = ImagePreprocessor.load_and_preprocess_for_model(img_path, target_size=512)\n",
    "        input_tensor = torch.from_numpy(img).unsqueeze(0).float().to(self.device)\n",
    "        overlays = { \"original_display_image\": torch.from_numpy(original_image).float() }\n",
    "        with torch.no_grad():\n",
    "            pred = self.seg_model(input_tensor).cpu().squeeze(0).numpy()\n",
    "        for i, region in enumerate(self.seg_model.targets):\n",
    "            heatmap = pred[i]\n",
    "            norm_heatmap = (heatmap - heatmap.min()) / (heatmap.max() - heatmap.min() + 1e-8)\n",
    "            mask = norm_heatmap >= ANATOMY_THRESHOLD\n",
    "            active_area = norm_heatmap.copy()\n",
    "            active_area[~mask] = np.nan\n",
    "            overlays[region] = torch.from_numpy(active_area).float()\n",
    "        print(f\"[{now}][API] Anatomical overlays generated.\")\n",
    "        return overlays\n",
    "\n",
    "    def process(self):\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        try:\n",
    "            img_path = self._get_image_for_processing()\n",
    "            original_image = ImagePreprocessor.load_and_preprocess_for_display(img_path)\n",
    "            results = self._analyze_pathologies(img_path)\n",
    "            json_path = os.path.join(self.output_path, f\"{self.id}.json\")\n",
    "            with open(json_path, \"w\") as f:\n",
    "                json.dump({\"id\": self.id, \"input_img\": os.path.basename(self.xray_file), \"results\": results}, f, indent=4)\n",
    "            print(f\"[{now}][API] Saved pathology results: {json_path}\")\n",
    "            disease_overlays = self._generate_disease_overlays(img_path, original_image)\n",
    "            save_file(disease_overlays, os.path.join(self.output_path, f\"DO-{self.id}.safetensors\"))\n",
    "            anatomical_overlays = self._generate_anatomical_overlays(img_path, original_image)\n",
    "            save_file(anatomical_overlays, os.path.join(self.output_path, f\"AO-{self.id}.safetensors\"))\n",
    "            print(f\"[{now}][API] Processing complete for ID: {self.id}\")\n",
    "            return self.id, results\n",
    "        except Exception as e:\n",
    "            print(f\"[{now}][API] Processing failed: {e}\")\n",
    "            return None\n",
    "\n",
    "# ------------------------\n",
    "# XRayVisualizer Class\n",
    "# ------------------------\n",
    "from safetensors.torch import load_file\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "import matplotlib.patheffects as path_effects\n",
    "\n",
    "class XRayVisualizer:\n",
    "    def __init__(self, uuid_str, output_path):\n",
    "        self.uuid = uuid_str\n",
    "        self.output_path = output_path\n",
    "        self.disease_results = None\n",
    "        self.disease_data = None\n",
    "        self.anatomical_data = None\n",
    "        self.base_image_display = None\n",
    "        self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        try:\n",
    "            json_path = os.path.join(self.output_path, f\"{self.uuid}.json\")\n",
    "            disease_path = os.path.join(self.output_path, f\"DO-{self.uuid}.safetensors\")\n",
    "            anatomy_path = os.path.join(self.output_path, f\"AO-{self.uuid}.safetensors\")\n",
    "            with open(json_path, \"r\") as f:\n",
    "                self.disease_results = json.load(f)[\"results\"]\n",
    "            self.disease_data = load_file(disease_path)\n",
    "            self.anatomical_data = load_file(anatomy_path)\n",
    "            self.base_image_display = self.disease_data[\"original_display_image\"].cpu().numpy()\n",
    "            if self.base_image_display.ndim == 2:\n",
    "                self.base_image_display = np.stack([self.base_image_display]*3, axis=-1)\n",
    "            print(f\"[{now}][API] Data loaded successfully for UUID: {self.uuid}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[{now}][API] Data loading failed: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_disease_results(self):\n",
    "        return self.disease_results\n",
    "\n",
    "    def show_overlays(self, keys, alphas=None, colormaps=None, return_bytes=False):\n",
    "        now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        if self.base_image_display is None:\n",
    "            print(f\"[{now}][API] Visualization failed: No base image\")\n",
    "            return None\n",
    "        alphas = alphas if alphas else VISUAL_ALPHAS\n",
    "        colormaps = colormaps if colormaps else VISUAL_COLORMAPS\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        composite_image = self.base_image_display.copy()\n",
    "        ax.imshow(composite_image)\n",
    "        ax.axis('off')\n",
    "        label_positions = []\n",
    "\n",
    "        def is_too_close(x, y):\n",
    "            for (ex, ey) in label_positions:\n",
    "                if np.sqrt((x-ex)**2 + (y-ey)**2) < LABEL_MIN_DIST:\n",
    "                    return True\n",
    "            return False\n",
    "\n",
    "        for key, alpha, cmap in zip(keys, alphas, colormaps):\n",
    "            overlay_tensor = self.disease_data.get(key) or self.anatomical_data.get(key)\n",
    "            if overlay_tensor is None:\n",
    "                print(f\"[{now}][API] Warning: Key '{key}' not found\")\n",
    "                continue\n",
    "            overlay_data = overlay_tensor.cpu().numpy()\n",
    "            if key in self.disease_data:\n",
    "                heatmap_rgb = overlay_data\n",
    "                valid_mask = np.any(heatmap_rgb != 0, axis=-1)\n",
    "            else:\n",
    "                heatmap_rgba = cmap(overlay_data)\n",
    "                heatmap_rgb = heatmap_rgba[..., :3]\n",
    "                valid_mask = (~np.isnan(overlay_data)) & (np.sum(heatmap_rgb, axis=-1) > 0)\n",
    "            for c in range(3):\n",
    "                composite_image[...,c][valid_mask] = (1-alpha)*composite_image[...,c][valid_mask] + alpha*heatmap_rgb[...,c][valid_mask]\n",
    "            if np.any(valid_mask):\n",
    "                intensity_map = np.mean(overlay_data, axis=2) if overlay_data.ndim==3 else overlay_data\n",
    "                max_idx = np.nanargmax(intensity_map)\n",
    "                max_y, max_x = np.unravel_index(max_idx, intensity_map.shape)\n",
    "                label_x, label_y = max_x, max_y\n",
    "                attempts=0\n",
    "                while is_too_close(label_x, label_y):\n",
    "                    label_x += LABEL_OFFSET_STEP\n",
    "                    label_y += LABEL_OFFSET_STEP\n",
    "                    attempts += 1\n",
    "                    if attempts>10: break\n",
    "                label_positions.append((label_x,label_y))\n",
    "                label_text = f\"{'Disease' if key in self.disease_data else 'Anatomy'}: {key}\"\n",
    "                txt = ax.text(label_x, label_y, label_text, color='white', fontsize=LABEL_FONTSIZE,\n",
    "                              weight='bold', ha='center', va='center')\n",
    "                txt.set_path_effects([path_effects.Stroke(linewidth=2, foreground='black'), path_effects.Normal()])\n",
    "        ax.imshow(np.clip(composite_image,0,1))\n",
    "        fig.subplots_adjust(left=0,right=1,top=1,bottom=0)\n",
    "\n",
    "        if return_bytes:\n",
    "            from io import BytesIO\n",
    "            img_io = BytesIO()\n",
    "            canvas = FigureCanvas(fig)\n",
    "            canvas.print_png(img_io)\n",
    "            plt.close(fig)\n",
    "            img_io.seek(0)\n",
    "            print(f\"[{now}][API] Visualization rendered to bytes\")\n",
    "            return img_io\n",
    "        else:\n",
    "            plt.show()\n",
    "            print(f\"[{now}][API] Visualization complete\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "515f8428-c000-440e-95d1-34565e0e15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFILE = r\"00000022_001.jpg\"\n",
    "OUTFILE = r\"xray_output\"\n",
    "\n",
    "# Predefined list of colormaps for overlays in visualization\n",
    "PREDEFINED_COLORMAPS = [\n",
    "    cm.jet, cm.viridis, cm.plasma, cm.inferno, cm.magma,\n",
    "    cm.cividis, cm.cool, cm.hot, cm.spring, cm.summer\n",
    "]\n",
    "\n",
    "selected_diseases = [\"Lung Opacity\", \"Pneumonia\", \"Left Scapula\",\"Right Scapula\", \"Heart\",\"Right Lung\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ca79765-7db1-44d6-8b97-3fd8c0296ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-14 03:04:52][API] Output directory ensured: xray_output\n",
      "[2025-09-14 03:04:52][API] Using device: cpu\n",
      "[2025-09-14 03:04:54][API] Copied image: xray_output\\test123.jpg\n",
      "[2025-09-14 03:04:54][API] Analyzing image for pathologies: xray_output\\test123.jpg\n",
      "[2025-09-14 03:04:54][API] Pathology analysis complete.\n",
      "[2025-09-14 03:04:54][API] Saved pathology results: xray_output\\test123.json\n",
      "[2025-09-14 03:04:55][API] Generating disease overlays.\n",
      "[2025-09-14 03:04:54][API] Processing failed: name 'DIISEASE_ALPHA' is not defined\n",
      "\n",
      "[2025-09-14 03:04:52] An unexpected error occurred: cannot unpack non-iterable NoneType object\n",
      "----- FAIL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Example Usage (Cell 1: Processing) ---\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    now = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    try:\n",
    "\n",
    "        processor = XRayProcessor(INFILE, OUTFILE, 'test123')\n",
    "        processed_uuid, results = processor.process()\n",
    "\n",
    "        if processed_uuid:\n",
    "            print(f\"\\n[{now}] Processing complete. The ID '{processed_uuid}' is ready for visualization.\")\n",
    "            print(f\"Copy the ID and run the code in the next cell to visualize the results.\")\n",
    "            print(f\"\\n[{now}] Overall process status\\n----- PASS\\n\")\n",
    "        else:\n",
    "            print(f\"[{now}] Overall process status\\n----- FAIL: X-ray processing failed.\\n\")\n",
    "\n",
    "    except (FileNotFoundError, ValueError, RuntimeError) as e:\n",
    "        print(f\"\\n[{now}] An error occurred: {e}\\n----- FAIL\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[{now}] An unexpected error occurred: {e}\\n----- FAIL\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32fef66-3401-4efb-9b6a-f38380e20acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "try:\n",
    "    # Define transparency and colormaps for each overlay key\n",
    "    alphas = [0.5] * len(selected_diseases)\n",
    "    colormaps = [PREDEFINED_COLORMAPS[i % len(PREDEFINED_COLORMAPS)] for i in range(len(selected_diseases))]\n",
    "\n",
    "    # Create visualizer instance\n",
    "    visualizer = XRayVisualizer(processed_uuid, OUTFILE)\n",
    "    \n",
    "    # Generate the overlay image bytes for the selected diseases\n",
    "    image_io = visualizer.show_overlays(\n",
    "        keys=selected_diseases,\n",
    "        alphas=alphas,\n",
    "        colormaps=colormaps,\n",
    "        return_bytes=True  # ensure the method returns image bytes\n",
    "    )\n",
    "\n",
    "    if image_io:\n",
    "        # Load image from bytes\n",
    "        image = Image.open(image_io)\n",
    "        # Display image inline in Jupyter notebook\n",
    "        display(image)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] render_overlay failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c002b0f-ee2b-44ab-b3d0-94bd181fbe94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67707019-2db8-457e-95c5-8b7c234ad9d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6e9b5a-ac8f-41f6-980f-a45b6f0cbba2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
